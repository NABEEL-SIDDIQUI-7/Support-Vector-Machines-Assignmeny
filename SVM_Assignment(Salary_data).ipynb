{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fdd4d64",
   "metadata": {},
   "source": [
    "Classify the Size_Categorie using SVM\n",
    "\n",
    "Attributes:\n",
    "\n",
    "month month of the year: 'jan' to 'dec'\n",
    "\n",
    "day :: day of the week: 'mon' to 'sun'\n",
    "\n",
    "FFMC ::FFMC index from the FWI system: 18.7 to 96.20\n",
    "\n",
    "DMC :: DMC index from the FWI system: 1.1 to 291.3\n",
    "\n",
    "DC ::DC index from the FWI system: 7.9 to 860.6\n",
    "\n",
    "ISI ::ISI index from the FWI system: 0.0 to 56.10\n",
    "\n",
    "temp:: temperature in Celsius degrees: 2.2 to 33.30\n",
    "\n",
    "RH ::relative humidity in %: 15.0 to 100\n",
    "\n",
    "wind ::wind speed in km/h: 0.40 to 9.40\n",
    "\n",
    "rain ::outside rain in mm/m2 : 0.0 to 6.4\n",
    "\n",
    "Size_Categorie the burned area of the forest ( Small , Large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfcd141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abce089",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SalaryData_Train(1).csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8688\\2304424781.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Loding data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msalary_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SalaryData_Train(1).csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msalary_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SalaryData_Train(1).csv'"
     ]
    }
   ],
   "source": [
    "#Loding data\n",
    "salary_train = pd.read_csv('SalaryData_Train(1).csv')\n",
    "salary_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_test = pd.read_csv('D:/ExcelR/Assignment/Support Vector Machines/SalaryData_Test(1).csv')\n",
    "salary_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b03ac",
   "metadata": {},
   "source": [
    "Conventionally, We perform EDA, visualisation and then split data into train and test. However, here we have train and test sets in first place only.. so we will merge them, perform EDA and visualisation.. and then again split data in order to apply ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75634c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate Train and Test datasets\n",
    "salary = salary_train.append(salary_test)\n",
    "salary.reset_index(inplace=True)\n",
    "salary = salary.drop(['index'], axis=1) \n",
    "salary.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34941b5",
   "metadata": {},
   "source": [
    "Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c602093",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273694e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "salary.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa027ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Types of variables\n",
    "\n",
    "numeric_features = [feature for feature in salary.columns if salary[feature].dtypes != 'O']\n",
    "print('numeric features:', numeric_features, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ea1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#under numeric features there are 2 types of features ie. discrete and categorical\n",
    "\n",
    "discrete_features = [feature for feature in numeric_features if len(salary[feature].unique())<25]\n",
    "print('discrete features:', discrete_features, '\\n')\n",
    "\n",
    "continuous_features = [feature for feature in numeric_features if feature not in discrete_features]\n",
    "print('continuous features:', continuous_features, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features\n",
    "\n",
    "categorical_features = [feature for feature in salary.columns if salary[feature].dtypes == 'O']\n",
    "print('categorical_features:', categorical_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7425d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency counts of values in categorical variables\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(salary[feature].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cardinality in categorical variables\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(feature, 'has', len(salary[feature].unique()), 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5702f7",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc16c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for continuous features -- Boxplot\n",
    "fig, axes=plt.subplots(4,1,figsize=(14,8))\n",
    "\n",
    "sns.boxplot(salary.age,  ax=axes[0])\n",
    "sns.boxplot(salary.capitalgain,data=salary ,  ax=axes[1])\n",
    "sns.boxplot(salary.capitalloss,  ax=axes[2])\n",
    "sns.boxplot(salary.hoursperweek,  ax=axes[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964eb2a7",
   "metadata": {},
   "source": [
    "There are lot of outliers present in the dataframe but we can't drop them because they are present in a very large quantity and can be important for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorical_features -- barplot\n",
    "fig, axes=plt.subplots(len(categorical_features),1,figsize=(14,50))\n",
    "\n",
    "for i in range (0, len(categorical_features)):\n",
    "    sns.countplot(salary[categorical_features[i]],ax=axes[i], order=salary[categorical_features[i]].value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5afbaf",
   "metadata": {},
   "source": [
    "Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_more_than_50=pd.DataFrame()\n",
    "salary_less_than_50=pd.DataFrame()\n",
    "\n",
    "salary_more_than_50 = salary.loc[salary['Salary']==' >50K']\n",
    "\n",
    "salary_less_than_50 = salary.loc[salary['Salary']==' <=50K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e32cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab930a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(salary_less_than_50.shape[0] + salary_more_than_50.shape[0]) ==salary.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b6941",
   "metadata": {},
   "source": [
    "Age distribution wrt salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15,14))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.hist(salary_more_than_50.age, bins=[10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "plt.title('Age of those with salary_more_than_50k')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.hist(salary_less_than_50.age, color = \"orange\", bins=[10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "plt.title('Age of those with salary_less_than_50k')\n",
    "\n",
    "\n",
    "age_describe = pd.DataFrame()\n",
    "\n",
    "age_describe['Age of those with salary_more_than_50k'] = salary_more_than_50['age'].describe()\n",
    "age_describe['Age of those with salary_less_than_50k'] = salary_less_than_50['age'].describe()\n",
    "\n",
    "age_describe  = age_describe.drop(['count', '25%', '50%', '75%'])\n",
    "plt.subplot(3,1,2)\n",
    "age_describe.plot.bar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f6b806",
   "metadata": {},
   "source": [
    "Insight:\n",
    "\n",
    "Age of those with salary more than 50K: Most of the people are in the age group of 30 - 50 and no one is below 20yrs\n",
    "\n",
    "Age of those with salary less than 50K: As age increases, no of people are decreasing.\n",
    "\n",
    "Hours/week distribution wrt salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,14))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.hist(salary_more_than_50.hoursperweek)\n",
    "plt.title('Hours/week of those with salary_more_than_50k')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.hist(salary_less_than_50.hoursperweek, color = \"orange\")\n",
    "plt.title('Hours/week of those with salary_less_than_50k')\n",
    "\n",
    "\n",
    "Hoursweek_describe = pd.DataFrame()\n",
    "\n",
    "Hoursweek_describe['Hours/week of those with salary_more_than_50k'] = salary_more_than_50['hoursperweek'].describe()\n",
    "Hoursweek_describe['Hours/week of those with salary_less_than_50k'] = salary_less_than_50['hoursperweek'].describe()\n",
    "\n",
    "Hoursweek_describe = Hoursweek_describe.drop(['count', '25%', '50%', '75%'])\n",
    "plt.subplot(3,1,2)\n",
    "Hoursweek_describe.plot.bar()\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a62b48",
   "metadata": {},
   "source": [
    "nsight:\n",
    "\n",
    "For both groups, majority is working for 30 to 40 hrs per week, and people working for 80 to 90 hrs is present in both groups\n",
    "\n",
    "Capital Gains distribution wrt salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bbd44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,14))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.hist(salary_more_than_50.capitalgain)\n",
    "plt.title('capitalgain of those with salary_more_than_50k')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.hist(salary_less_than_50.capitalgain, color = \"orange\")\n",
    "plt.title('capitalgain of those with salary_less_than_50k')\n",
    "\n",
    "\n",
    "capitalgain_describe = pd.DataFrame()\n",
    "\n",
    "capitalgain_describe['capitalgain of those with salary_more_than_50k'] = salary_more_than_50['capitalgain'].describe()\n",
    "capitalgain_describe['capitalgain of those with salary_less_than_50k'] = salary_less_than_50['capitalgain'].describe()\n",
    "\n",
    "capitalgain_describe = capitalgain_describe.drop(['count', '25%', '50%', '75%'])\n",
    "plt.subplot(3,1,2)\n",
    "capitalgain_describe.plot.bar()\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b89f6a",
   "metadata": {},
   "source": [
    "Insight:\n",
    "\n",
    "Salary more than 50k: Capital gain for majority is between 0 to 1000\n",
    "\n",
    "Salary less than 50k: capital gain for majority is less than 500\n",
    "\n",
    "Capital Loss distribution wrt salary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,14))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.hist(salary_more_than_50.capitalloss)\n",
    "plt.title('capitalloss of those with salary_more_than_50k')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.hist(salary_less_than_50.capitalloss, color = \"orange\")\n",
    "plt.title('capitalloss of those with salary_less_than_50k')\n",
    "\n",
    "\n",
    "capitalloss_describe = pd.DataFrame()\n",
    "\n",
    "capitalloss_describe['capitalloss of those with salary_more_than_50k'] = salary_more_than_50['capitalloss'].describe()\n",
    "capitalloss_describe['capitalloss of those with salary_less_than_50k'] = salary_less_than_50['capitalloss'].describe()\n",
    "\n",
    "capitalloss_describe = capitalloss_describe.drop(['count', '25%', '50%', '75%'])\n",
    "plt.subplot(3,1,2)\n",
    "capitalloss_describe.plot.bar()\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b979507",
   "metadata": {},
   "source": [
    "Categorical variables wrt salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ceb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "categorical_features.remove('Salary') #removing column salary since it is output variable itself. \n",
    "\n",
    "for feature in categorical_features:\n",
    "    df = pd.DataFrame()\n",
    "    df['More than 50k'] = salary[salary['Salary'] == ' >50K'][feature].value_counts()\n",
    "    df['Less than 50k'] = salary[salary['Salary'] == ' <=50K'][feature].value_counts()\n",
    "    \n",
    "    df.plot.bar(figsize=(14,6))\n",
    "    \n",
    "    j = j + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1224206",
   "metadata": {},
   "source": [
    "Insight:\n",
    "\n",
    "Majority of both the groups is employed in private sectors\n",
    "\n",
    "As educational qualification decreases, no. of people in group of 'salary more than 50k' reduces.\n",
    "\n",
    "Majority of people having salary more than 50k are married, whereas very small proportion of them is never married, divorced, widow, separated. Significant proportion of people having salary less than 50k are never married, divorced, widow, separated.\n",
    "\n",
    "Most of the people having salary less than 50k are engaged in manual and low skilled work like craft repair, clerk, transport, machine inspection, farming fishing, handlers cleaners and other services. Whereas people having salary more than 50k are in high skilled works like managers, professors, sales\n",
    "\n",
    "Insignificant amount of non natives are having salary more than 50k\n",
    "\n",
    "Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary1 = salary.copy() \n",
    "salary1.drop('Salary',axis=1, inplace =True) \n",
    "salary1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fefcdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical 'input' column\n",
    "salary1 = pd.get_dummies(salary1)\n",
    "salary1.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7233581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary1['Salary'] = salary.Salary\n",
    "salary1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# encoding categorical 'output' column\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(salary1.Salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary1.Salary = encoder.transform(salary1.Salary)\n",
    "salary1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b262a1",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_train.shape #salary.train is original train set provided by ExcelR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_test.shape #salary.test is original train set provided by ExcelR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a842c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#we concatenated both train n test set for EDA and Visualisation.\n",
    "# now lets separate them. first 30161 entries form train set and rest 15060 entries are test set.\n",
    "\n",
    "train_set = salary1.iloc[:30161, :]\n",
    "test_set = salary1.iloc[30161:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e15347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of new dataframes - {} , {}\".format(train_set.shape, test_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set.iloc[:,:102]\n",
    "x_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04971d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = train_set.loc[:,['Salary']]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0430aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457407b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_set.iloc[:,:102]\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d816e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_set.loc[:,['Salary']]\n",
    "y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train: \",x_train.shape)\n",
    "print(\"Shape of X_test: \", x_test.shape)\n",
    "print(\"Shape of y_train: \",y_train.shape)\n",
    "print(\"Shape of y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8b0f7",
   "metadata": {},
   "source": [
    "SVM with default hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "pred = classifier.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, pred) \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a500746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV for optimum hyper parameters taking too long to compute.. so we go with default hyper parameters\n",
    "print(classification_report(y_test, pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ed9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, pred), annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae01d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_test,pred)\n",
    "print('AUC-ROC Score:',auc)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
